{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning import miners, losses\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from data_utils import *\n",
    "from train_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = {\n",
    "    'IMG_WIDTH': 256,\n",
    "    'IMG_HEIGHT': 256,\n",
    "    'TRAINING_DATASET_DIR': '../Week 1/data/MIT_split/train',\n",
    "    'TEST_DATASET_DIR': '../Week 1/data/MIT_split/test',\n",
    "    'batch_size': 16,\n",
    "    'epochs': 2,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = CustomTransform(config, mode='train')\n",
    "transform_test = CustomTransform(config, mode='test')\n",
    "\n",
    "train_dataset = PairDataset(datasets.ImageFolder(root=config['TRAINING_DATASET_DIR'], transform=transform_train))\n",
    "test_dataset =  PairDataset(datasets.ImageFolder(root=config['TEST_DATASET_DIR'], transform=transform_test))\n",
    "\n",
    "total_length = len(train_dataset)\n",
    "train_size = int(0.8 * total_length)  # e.g., 80% for training\n",
    "valid_size = total_length - train_size  # remaining 20% for validation\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, validation_dataset = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "dataloader_validation = DataLoader(validation_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition remains the same\n",
    "class SiameseNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights='ResNet50_Weights.DEFAULT').eval()\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output1 = self.model(x1)\n",
    "        output2 = self.model(x2)\n",
    "        return output1, output2\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Luis/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "  0%|          | 0/94 [00:28<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2048]) torch.Size([16, 2048]) torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_10824\\841626648.py\", line 15, in <module>\n",
      "    train_loss = train(model, dataloader_train, optimizer, loss_func, miner, config['device'])\n",
      "  File \"c:\\Users\\Luis\\Documents\\Universidad\\MCV\\C5\\MCV-C5\\Week 3\\train_utils.py\", line 17, in train\n",
      "    hard_pairs = miner(outputs1, outputs2, targets)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\pytorch_metric_learning\\miners\\base_miner.py\", line 49, in forward\n",
      "    c_f.check_shapes(embeddings, labels)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\pytorch_metric_learning\\utils\\common_functions.py\", line 393, in check_shapes\n",
      "    raise ValueError(\"labels must be a 1D tensor of shape (batch_size,)\")\n",
      "ValueError: labels must be a 1D tensor of shape (batch_size,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\Luis\\miniconda3\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "model = SiameseNetwork()\n",
    "model.to(config['device'])\n",
    "\n",
    "# Using Contrastive Loss as before\n",
    "loss_func = losses.ContrastiveLoss(pos_margin=0, neg_margin=1)\n",
    "\n",
    "# Integrating PairMarginMiner\n",
    "miner = miners.PairMarginMiner(pos_margin=0.2, neg_margin=0.8)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "# Adjusted Training Loop with Miner\n",
    "for epoch in range(config['epochs']):\n",
    "\n",
    "    train_loss = train(model, dataloader_train, optimizer, loss_func, miner, config['device'])\n",
    "    val_loss = validate(model, dataloader_validation, loss_func, miner, config['device'])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
