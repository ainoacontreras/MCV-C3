{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning import miners, losses, distances\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from data_utils import *\n",
    "from train_utils import *\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "config = {\n",
    "    'IMG_WIDTH': 256,\n",
    "    'IMG_HEIGHT': 256,\n",
    "    'TRAINING_DATASET_DIR': '../Week 1/data/MIT_split/train',\n",
    "    'TEST_DATASET_DIR': '../Week 1/data/MIT_split/test',\n",
    "    'batch_size': 16,\n",
    "    'epochs': 2,\n",
    "    'learning_rate': 0.001,\n",
    "    'n_neighbors': 5,\n",
    "    'type_model': 'siamese',\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = CustomTransform(config, mode='train')\n",
    "transform_test = CustomTransform(config, mode='test')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=config['TRAINING_DATASET_DIR'], transform=transform_train)\n",
    "test_dataset =  datasets.ImageFolder(root=config['TEST_DATASET_DIR'], transform=transform_test)\n",
    "\n",
    "total_length = len(train_dataset)\n",
    "train_size = int(0.8 * total_length)  # e.g., 80% for training\n",
    "valid_size = total_length - train_size  # remaining 20% for validation\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, validation_dataset = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "dataloader_validation = DataLoader(validation_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition remains the same\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights='ResNet50_Weights.DEFAULT')\n",
    "        self.model.fc = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = Net()\n",
    "model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = distances.LpDistance(power=2)\n",
    "\n",
    "if config['type_model'] == 'siamese':\n",
    "    loss_func = losses.ContrastiveLoss(pos_margin=0.2, neg_margin=0.8, distance=distance)\n",
    "    miner = miners.PairMarginMiner(pos_margin=0.2, neg_margin=0.8)\n",
    "\n",
    "else:\n",
    "    loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance)\n",
    "    miner = miners.TripletMarginMiner(margin=0.2, distance=distance, type_of_triplets=\"semihard\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\", 'mean_average_precision'), k=config['n_neighbors'])\n",
    "\n",
    "best_acc = 0\n",
    "# Adjusted Training Loop with Miner\n",
    "for epoch in range(config['epochs']):\n",
    "\n",
    "    train_loss = train(model, dataloader_train, optimizer, loss_func, miner, config['device'], config['type_model'])\n",
    "    accuracies = test(model, train_dataset, validation_dataset, accuracy_calculator)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Validation Acc: {accuracies['precision_at_1']}\")\n",
    "    \n",
    "    # wandb.log({'Train Loss': train_loss, 'Validation Acc': accuracies['precision_at_1'], 'MAP': accuracies['mean_average_precision']})\n",
    "\n",
    "    if accuracies['precision_at_1'] > best_acc:\n",
    "        best_acc = accuracies['precision_at_1']\n",
    "        torch.save(model.state_dict(), 'pretrained/best_model_siamese.pth')\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing the model...\")\n",
    "test_accuracies = test(model, train_dataset, test_dataset, accuracy_calculator)\n",
    "print(f\"Test Accuracy: {test_accuracies['precision_at_1']}, MAP: {test_accuracies['mean_average_precision']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
